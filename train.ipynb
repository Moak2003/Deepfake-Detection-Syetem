{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google_drive_downloader'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/ll/__c7qsrd5dg9t48zc6glz3z00000gn/T/ipykernel_25114/4163646482.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle_drive_downloader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGoogleDriveDownloader\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mgdd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'1ubvKLzBDe5i1acxgGUK6ObeNBYCKUS07'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mgdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload_file_from_google_drive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdest_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'./data.zip'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0munzip\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google_drive_downloader'"
     ]
    }
   ],
   "source": [
    "from google_drive_downloader import GoogleDriveDownloader as gdd\n",
    "url = '1ubvKLzBDe5i1acxgGUK6ObeNBYCKUS07'\n",
    "gdd.download_file_from_google_drive(file_id = url,dest_path='./data.zip',unzip=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import face_recognition\n",
    "def validate_video(vid_path,train_transforms):\n",
    "      transform = train_transforms\n",
    "      count = 20\n",
    "      video_path = vid_path\n",
    "      frames = []\n",
    "      a = int(100/count)\n",
    "      first_frame = np.random.randint(0,a)\n",
    "      temp_video = video_path.split('/')[-1]\n",
    "      for i,frame in enumerate(frame_extract(video_path)):\n",
    "        frames.append(transform(frame))\n",
    "        if(len(frames) == count):\n",
    "          break\n",
    "      frames = torch.stack(frames)\n",
    "      frames = frames[:count]\n",
    "      return frames\n",
    "def frame_extract(path):\n",
    "  vidObj = cv2.VideoCapture(path) \n",
    "  success = 1\n",
    "  while success:\n",
    "      success, image = vidObj.read()\n",
    "      if success:\n",
    "          yield image\n",
    "im_size = 112\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "                                        transforms.ToPILImage(),\n",
    "                                        transforms.Resize((im_size,im_size)),\n",
    "                                        transforms.ToTensor(),\n",
    "                                        transforms.Normalize(mean,std)])\n",
    "video_fil =  glob.glob('/content/drive/My Drive/Celeb_fake_face_only/*.mp4')\n",
    "video_fil += glob.glob('/content/drive/My Drive/Celeb_real_face_only/*.mp4')\n",
    "video_fil += glob.glob('/content/drive/My Drive/DFDC_FAKE_Face_only_data/*.mp4')\n",
    "video_fil += glob.glob('/content/drive/My Drive/DFDC_REAL_Face_only_data/*.mp4')\n",
    "video_fil += glob.glob('/content/drive/My Drive/FF_Face_only_data/*.mp4')\n",
    "print(\"Total no of videos :\" , len(video_fil))\n",
    "print(video_fil)\n",
    "count = 0;\n",
    "for i in video_fil:\n",
    "  try:\n",
    "    count+=1\n",
    "    validate_video(i,train_transforms)\n",
    "  except:\n",
    "    print(\"Number of video processed: \" , count ,\" Remaining : \" , (len(video_fil) - count))\n",
    "    print(\"Corrupted video is : \" , i)\n",
    "    continue\n",
    "print((len(video_fil) - count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the video name and labels from csv\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import face_recognition\n",
    "class video_dataset(Dataset):\n",
    "    def __init__(self,video_names,labels,sequence_length = 60,transform = None):\n",
    "        self.video_names = video_names\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.count = sequence_length\n",
    "    def __len__(self):\n",
    "        return len(self.video_names)\n",
    "    def __getitem__(self,idx):\n",
    "        video_path = self.video_names[idx]\n",
    "        frames = []\n",
    "        a = int(100/self.count)\n",
    "        first_frame = np.random.randint(0,a)\n",
    "        temp_video = video_path.split('/')[-1]\n",
    "        label = self.labels.iloc[(labels.loc[labels[\"file\"] == temp_video].index.values[0]),1]\n",
    "        if(label == 'FAKE'):\n",
    "          label = 0\n",
    "        if(label == 'REAL'):\n",
    "          label = 1\n",
    "        for i,frame in enumerate(self.frame_extract(video_path)):\n",
    "          frames.append(self.transform(frame))\n",
    "          if(len(frames) == self.count):\n",
    "            break\n",
    "        frames = torch.stack(frames)\n",
    "        frames = frames[:self.count]q\n",
    "        #print(\"length:\" , len(frames), \"label\",label)\n",
    "        return frames,label\n",
    "    def frame_extract(self,path):\n",
    "      vidObj = cv2.VideoCapture(path) \n",
    "      success = 1\n",
    "      while success:\n",
    "          success, image = vidObj.read()\n",
    "          if success:\n",
    "              yield image\n",
    "#plot the image\n",
    "def im_plot(tensor):\n",
    "    image = tensor.cpu().numpy().transpose(1,2,0)\n",
    "    b,g,r = cv2.split(image)\n",
    "    image = cv2.merge((r,g,b))\n",
    "    image = image*[0.22803, 0.22145, 0.216989] +  [0.43216, 0.394666, 0.37645]\n",
    "    image = image*255.0\n",
    "    plt.imshow(image.astype(int))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frame_extract(path):\n",
    "  vidObj = cv2.VideoCapture(path) \n",
    "  success = 1\n",
    "  while success:\n",
    "      success, image = vidObj.read()\n",
    "      if success:\n",
    "          yield image\n",
    "!pip3 install face_recognition\n",
    "!mkdir '/content/drive/My Drive/FF_REAL_Face_only_data'\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import face_recognition\n",
    "from tqdm.autonotebook import tqdm\n",
    "def create_face_videos(path_list,out_dir):\n",
    "  already_present_count =  glob.glob(out_dir+'*.mp4')\n",
    "  print(\"No of videos already present \" , len(already_present_count))\n",
    "  for path in tqdm(path_list):\n",
    "    out_path = os.path.join(out_dir,path.split('/')[-1])\n",
    "    file_exists = glob.glob(out_path)\n",
    "    if(len(file_exists) != 0):\n",
    "      print(\"File Already exists: \" , out_path)\n",
    "      continue\n",
    "    frames = []\n",
    "    flag = 0\n",
    "    face_all = []\n",
    "    frames1 = []\n",
    "    out = cv2.VideoWriter(out_path,cv2.VideoWriter_fourcc('M','J','P','G'), 30, (112,112))\n",
    "    for idx,frame in enumerate(frame_extract(path)):\n",
    "      if(idx <= 150):\n",
    "        frames.append(frame)\n",
    "        if(len(frames) == 4):\n",
    "          faces = face_recognition.batch_face_locations(frames)\n",
    "          for i,face in enumerate(faces):\n",
    "            if(len(face) != 0):\n",
    "              top,right,bottom,left = face[0]\n",
    "            try:\n",
    "              out.write(cv2.resize(frames[i][top:bottom,left:right,:],(112,112)))\n",
    "            except:\n",
    "              pass\n",
    "          frames = []\n",
    "    try:\n",
    "      del top,right,bottom,left\n",
    "    except:\n",
    "      pass\n",
    "    out.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c093380f7d5debbcaa440089ef332b1954648df85cd3d726759408d591e41db5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
